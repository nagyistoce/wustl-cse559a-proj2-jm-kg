<html xmlns="http://www.w3.org/1999/xhtml">
<font face="Courier New" size="2">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>Face Recognition</title>

<STYLE TYPE="text/css">
table{border-collapse:collapse;}
table, td, th{border:1px solid black;}
td{padding:5px;font-family: Courier New; font-size: 10pt;}
th{padding:5px;font-family: Courier New; font-size: 11pt;}
p{font-family: Courier New; font-size: 10pt;}
h3{font-family: Courier New; font-size: 12pt;}
</STYLE>
</head>

<body>
<h1>Face Recognition</h1>
<h3>By Kurt Glastetter, Josh Mason</h3>
Link to source: <a href="">Source</a><br>

<h2>Description</h2>

<p>
For this project, we compared various techniques for face recognition.  We focused our efforts on Principal Component Analysis and Mean Face comparison.  We experimented using different pre-processing techniques before performing PCA as well as testing different measures of similarity and modifying the value of <i>k</i> in k-Nearest Neighbor.</p>

<p>We used k-Nearest Neighbor to attempt to match a face with the subject it most closely related to.  kNN works by finding the neighbors that are "closest" to a test image and picking the neighbor that is most frequent as its best match.  The value of <i>k</i> determines how many neighbors will be analyzed when trying to pick a match.  In order for kNN to work, a measure of similarity between the test image and all training images needs to be computed.  These results are then sorted and the top <i>k</i> neighbors are chosen.  The neighbors in our algorithm are the list of images that were the closest match to the test image. Because each person has multiple images for them, we determine which person showed up most frequently, and say that is who the test image most closely matches.</p>

<p>We tried four different measures of similarity before using its results to find the nearest neighbor. The similarity measures we tried using were:</p>
<ul>
	<li>Euclidian Distance (<a href="http://en.wikipedia.org/wiki/Euclidean_distance">info</a>)</li><br>
	Euclidian Distance (ED) performed the best compared to the other measures of similarity that we experimented with.
	<br><br>
	<li>Normalized Euclidian Distance (<a href="http://www.tsi.enst.fr/tsi/enseignement/ressources/mti/classif-textures/node4.html">info</a>)</li><br>
	Normalized Euclidian Distance (NED) performed exactly the same as ED did in all of our experiments.
	<br><br>
	<li>Cosine Similarity (<a href="http://en.wikipedia.org/wiki/Cosine_similarity">info</a>)</li><br>
	Cosine (CS) performed poorly in all of our experiments.  It's results are not shown in any of our tables below because it's results are not worth showing.  It performed better than chance, but only marginally.  It was not a good measure of similarity here.  This is not suprising as CS tends to be the preferred technique for comparing text and not faces or coefficients from PCA.
	<br><br>
	<li>Mahalanobis Distance (<a href="http://en.wikipedia.org/wiki/Mahalanobis_distance">info</a>)</li><br>
	Mahalanobis Distance (MD) performed extermely bad.  It performed as good as chance, but no better.  It's possible we implemented MD incorrectly or that MD really is just not a good measure of similarity for comparing coefficients.
</ul>

<del>describe PCA algorithm</del>

<del>describe mean face algorithm</del>

<h3>Extension 1 Description</h3>
<p>Description of extension 1.</p>

<h3>Extension 2 Description</h3>
<p><del>(general observations, histogram equalization helped achieve better results when using more coefficients, but decreased results in all other cases.  edge detection pretty much sucked and did worse than if we had just not used it.  histogram equalization with edge map overlayed performed better than no preprocessing, but worse than just histo eq.  obviously, edge detection brings down the results.  probably because information is being lost from the image.  we also tried blurring the image, but this also performed poorly, about as good as edge detection.  Likely for the same reason edge detection did bad.</del></p>

<h2>Base Results</h2>
<p>Below is a table showing our overall results.  The table below shows the results when we used Euclidian distance as our measure of similarity and <i>k=1</i> for the value of <i>k</i> in k-Nearest Neigbhor.</p>

<table border="1" title="Euclidian Distance Results">
<tr> <th>Method</th>             <th>Correct</th>        <th>Incorrect</th>        <th>% Correct</th> </tr>
<tr> <td>PCA 2 Coefficients</td> <td>6</td>              <td>34</td>               <td>15.0</td> </tr>
<tr> <td>PCA 4 Coefficients</td> <td>11</td>             <td>29</td>               <td>27.5</td> </tr>
<tr> <td>PCA 6 Coefficients</td> <td>14</td>             <td>26</td>               <td>35.0</td> </tr>
<tr> <td>PCA 9 Coefficients</td> <td>23</td>             <td>17</td>               <td>57.5</td> </tr>
<tr> <td>Mean Face</td>          <td>39</td>             <td>1</td>                <td>97.5</td> </tr>
</table>

<p>We tried many other combinations of similarity measures and modifying the value of <i>k</i>.  The table below shows the top 5 combinations obtained.  All the results below are for PCA only.  Since Euclidian distance was the best measurement of similarity, all the results below were obtained using Euclidian distance as the similarity measurement.</p>
<table border="1" title="Top Results">
<tr> <th>Method</th>             <th>Correct</th>        <th>Incorrect</th>        <th>% Correct</th> </tr>
<tr> <td>c=9,k=1,h</td>          <td>29</td>             <td>11</td>               <td>72.5</td> </tr>
<tr> <td>c=9,k=3,h</td>          <td>29</td>             <td>11</td>               <td>72.5</td> </tr>
<tr> <td>c=9,k=3,he</td>         <td>26</td>             <td>24</td>               <td>65.0</td> </tr>
<tr> <td>c=9,k=1,e</td>          <td>24</td>             <td>16</td>               <td>60.0</td> </tr>
<tr> <td>c=9,k=3,e</td>          <td>24</td>             <td>16</td>               <td>60.0</td> </tr>
</table>
In the table above, c=# of coefficients used, h=histogram equalization, e=edge map overlayed on image, he=histogram equalization performed, then edge map overlayed on top, k=# of neighbors examined.

<p>explanation of results</p>

<h2>Extension 1 Results</h2>
<p>Below is a table showing our overall results for our testing on the aligned labelled faces in the wild image set.  This uses only the center 70x100 face portion of the image.</p>
<table border="1" title="Euclidian Distance Results">
<tr> <th>Method</th>             <th>Correct</th>        <th>Incorrect</th>        <th>% Correct</th> </tr>
<tr> <td>PCA 2 Coefficients</td> <td>1</td>              <td>45</td>               <td>2.1</td>  </tr>
<tr> <td>PCA 4 Coefficients</td> <td>4</td>              <td>42</td>               <td>8.7</td>  </tr>
<tr> <td>PCA 6 Coefficients</td> <td>4</td>              <td>42</td>               <td>8.7</td>  </tr>
<tr> <td>PCA 9 Coefficients</td> <td>6</td>              <td>40</td>               <td>13.0</td> </tr>
<tr> <td>Mean Face</td>          <td>18</td>             <td>28</td>               <td>39.1</td> </tr>
</table>
<p>Below is a table showing our overall results for testing the aligned labelled faces in the wild, but by training with equal-sized data sets for each subject (18 images each).  The training images for each subject were chosen at random.  Again, only the center 70x100 face portion of the image was used.</p>
<table border="1" title="Euclidian Distance Results">
<tr> <th>Method</th>             <th>Correct</th>        <th>Incorrect</th>        <th>% Correct</th> </tr>
<tr> <td>PCA 2 Coefficients</td> <td>1</td>              <td>45</td>               <td>2.2</td>  </tr>
<tr> <td>PCA 4 Coefficients</td> <td>3</td>              <td>43</td>               <td>6.5</td>  </tr>
<tr> <td>PCA 6 Coefficients</td> <td>3</td>              <td>43</td>               <td>6.5</td>  </tr>
<tr> <td>PCA 9 Coefficients</td> <td>6</td>              <td>40</td>               <td>13.0</td> </tr>
<tr> <td>Mean Face</td>          <td>16</td>             <td>30</td>               <td>34.8</td> </tr>
</table>

<h2>Extension 2 Results</h2>
<p>Below is a table showing our overall results when trying using histogram equalization as a preprocessing step. The results were obtained using Euclidian distance and <i>k=1</i>.</p>
<table border="1" title="Histogram Equalization Results">
<tr> <th>Method</th>             <th>Correct</th>        <th>Incorrect</th>        <th>% Correct</th> </tr>
<tr> <td>PCA 2 Coefficients</td> <td>4</td>              <td>36</td>               <td>10.0</td> </tr>
<tr> <td>PCA 4 Coefficients</td> <td>6</td>              <td>34</td>               <td>15.0</td> </tr>
<tr> <td>PCA 6 Coefficients</td> <td>11</td>             <td>29</td>               <td>27.5</td> </tr>
<tr> <td>PCA 9 Coefficients</td> <td>29</td>             <td>11</td>               <td>72.5</td> </tr>
</table>

<p>Below is a table showing our overall results when using edge detection as a preprocessing step. The results were obtained using Euclidian distance and <i>k=1</i>.</p>
<table border="1" title="Edge Detection Preprocessing Results">
<tr> <th>Method</th>             <th>Correct</th>        <th>Incorrect</th>        <th>% Correct</th> </tr>
<tr> <td>PCA 2 Coefficients</td> <td>4</td>              <td>36</td>               <td>10.0</td> </tr>
<tr> <td>PCA 4 Coefficients</td> <td>6</td>              <td>34</td>               <td>15.0</td> </tr>
<tr> <td>PCA 6 Coefficients</td> <td>9</td>              <td>31</td>               <td>22.5</td> </tr>
<tr> <td>PCA 9 Coefficients</td> <td>12</td>             <td>28</td>               <td>30.0</td> </tr>
</table>

</body>

</font>
</html>
